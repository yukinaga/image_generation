{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvuZWiICwts7GO/vL5b9MI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/image_generation/blob/main/section_4/01_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74mqS_L8nq4"
      },
      "source": [
        "# GANの実装\n",
        "GANの実装を解説します。  \n",
        "GANではGeneratorとDiscriminaorを競い合わせるように訓練することで、Generatorは次第に本物の画像にそっくりの画像を生成するようになります。  \n",
        "Discriminatorの学習に用いる本物の画像には、手書き数字画像のデータセットを使います。  \n",
        "ノイズから画像が生成される過程を観察した上で、GeneratorとDiscriminaorが均衡することを確かめましょう。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7h50pYSRaZ0"
      },
      "source": [
        "## 手書き文字画像\n",
        "GANに用いる訓練用のデータを用意します。    \n",
        "scikit-learnから、8×8の手書き数字の画像データを読み込んで表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9WCis8TGwx"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "digits_data = datasets.load_digits()\n",
        "\n",
        "n_img = 10  # 表示する画像の数\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(n_img):\n",
        "    # 入力画像\n",
        "    ax = plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(digits_data.data[i].reshape(8, 8), cmap=\"Greys_r\")\n",
        "    ax.get_xaxis().set_visible(False)  # 軸を非表示に\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "print(\"データの形状:\", digits_data.data.shape)\n",
        "print(\"ラベル:\", digits_data.target[:n_img])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtujqB1gSh4I"
      },
      "source": [
        "## 各設定\n",
        "GANに必要な各設定を行います。  \n",
        "Generatorに入力するノイズの数はここで設定します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbSwlXZIUN7C"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# -- 各設定値 --\n",
        "img_size = 8  # 画像の高さと幅\n",
        "n_noise = 16  # ノイズの数\n",
        "n_mid_1 = 32  # 中間層のニューロン数\n",
        "n_mid_2 = 64  # 中間層のニューロン数\n",
        "\n",
        "eta = 0.001  # 学習係数\n",
        "epochs = 1001  # 学習回数\n",
        "interval = 50  # 経過の表示間隔\n",
        "batch_size = 16\n",
        "\n",
        "# -- 訓練データ --\n",
        "digits_data = datasets.load_digits()\n",
        "x_train = np.asarray(digits_data.data)\n",
        "x_train = x_train / 15*2-1  # -1から1の範囲\n",
        "t_train = digits_data.target\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float)\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYb9yszSURKH"
      },
      "source": [
        "## Generatorの構築\n",
        "PyTorchによりGeneratorのモデルを構築します。  \n",
        "出力層の活性化関数には、Discriminatorへの入力を-1から1の範囲にするためにtanhを使います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qfDQ8QJolyo"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mid_1 = nn.Linear(n_noise, n_mid_1)\n",
        "        self.mid_2 = nn.Linear(n_mid_1, n_mid_2)\n",
        "        self.out = nn.Linear(n_mid_2, img_size*img_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.mid_1(x))\n",
        "        x = F.relu(self.mid_2(x))\n",
        "        x = F.tanh(self.out(x))\n",
        "        return x\n",
        "\n",
        "generator = Generator()\n",
        "generator.cuda()  # GPU対応\n",
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtA6l8bpD9rw"
      },
      "source": [
        "## Discriminatorの構築\n",
        "PyTorchによりDiscriminatorのモデルを構築します。  \n",
        "出力層の活性化関数には、0から1までの値で本物かどうかを識別するためにsigmoid関数を使います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqGNtX2D97k"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mid_1 = nn.Linear(img_size*img_size, n_mid_2)\n",
        "        self.mid_2 = nn.Linear(n_mid_2, n_mid_1)\n",
        "        self.out = nn.Linear(n_mid_1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.mid_1(x))\n",
        "        x = F.relu(self.mid_2(x))\n",
        "        x = F.sigmoid(self.out(x))\n",
        "        return x\n",
        "\n",
        "discriminator = Discriminator()\n",
        "discriminator.cuda()  # GPU対応\n",
        "print(discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHM61pcsW6rY"
      },
      "source": [
        "### 画像の生成\n",
        "画像を生成して表示するための関数を定義します。  \n",
        "画像は、訓練済みのGenertorにノイズを入力することで生成されます。  \n",
        "画像は16×16枚生成されますが、並べて一枚の画像にした上で表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Waj3m0W-oo"
      },
      "source": [
        "# -- 画像を生成して表示 --\n",
        "def generate_images(i):\n",
        "    # 画像の生成\n",
        "    n_rows = 16  # 行数\n",
        "    n_cols = 16  # 列数\n",
        "    noise = torch.randn(n_rows * n_cols, n_noise).cuda()\n",
        "    g_imgs = generator(noise)\n",
        "    g_imgs = g_imgs/2 + 0.5  # 0-1の範囲にする\n",
        "    g_imgs = g_imgs.cpu().detach().numpy()\n",
        "\n",
        "    img_size_spaced = img_size + 2\n",
        "    matrix_image = np.zeros((img_size_spaced*n_rows, img_size_spaced*n_cols))  # 全体の画像\n",
        "\n",
        "    #  生成された画像を並べて一枚の画像にする\n",
        "    for r in range(n_rows):\n",
        "        for c in range(n_cols):\n",
        "            g_img = g_imgs[r*n_cols + c].reshape(img_size, img_size)\n",
        "            top = r*img_size_spaced\n",
        "            left = c*img_size_spaced\n",
        "            matrix_image[top : top+img_size, left : left+img_size] = g_img\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(matrix_image.tolist(), cmap=\"Greys_r\")\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MA9y1jWPo0D"
      },
      "source": [
        "## 正解数の計算\n",
        "Discriminatorによる鑑定の正解数を、カウントする関数を定義します。  \n",
        "Discriminatorの精度の計算に使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUJa7_wP2gN"
      },
      "source": [
        "def count_correct(y, t):\n",
        "    correct = torch.sum((torch.where(y<0.5, 0, 1) ==  t).float())\n",
        "    return correct.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC4f8NH6U86F"
      },
      "source": [
        "## 学習\n",
        "構築したGANのモデルを使って、学習を行います。  \n",
        "Generatorが生成した画像には正解ラベル0、本物の画像には正解ラベル1を与えてDiscriminatorを訓練します。  \n",
        "その後に、結合したモデルを使ってGeneratorを訓練しますが、この場合の正解ラベルは1になります。  \n",
        "これらの訓練を繰り返すことで、本物と見分けがつかない手書き文字画像が生成されるようになります。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOAs3rh2PJJ"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# 交差エントロピー誤差関数\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "# Adam\n",
        "optimizer_gen = optim.Adam(generator.parameters())\n",
        "optimizer_disc = optim.Adam(discriminator.parameters())\n",
        "\n",
        "# ログ\n",
        "error_record_fake = []  # 偽物画像の誤差記録\n",
        "acc_record_fake = []  # 偽物画像の精度記録\n",
        "error_record_real = []  # 本物画像の誤差記録\n",
        "acc_record_real = []  # 本物画像の精度記録\n",
        "\n",
        "# -- GANの学習 --\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "for i in range(epochs):\n",
        "    loss_fake = 0  # 誤差\n",
        "    correct_fake = 0  # 正解数\n",
        "    loss_real = 0\n",
        "    correct_real = 0\n",
        "    n_total = 0  # データの総数（精度の計算に使用）\n",
        "    for j, (x,) in enumerate(train_loader):  # ミニバッチ（x,）を取り出す\n",
        "\n",
        "        n_total += x.size()[0]  # バッチサイズを累積\n",
        "\n",
        "        # ノイズから画像を生成しDiscriminatorを訓練\n",
        "        noise = torch.randn(x.size()[0], n_noise).cuda()\n",
        "        imgs_fake = generator(noise)  # 画像の生成\n",
        "        t = torch.zeros(x.size()[0], 1).cuda()  # 正解は0\n",
        "        y = discriminator(imgs_fake)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
        "        loss_fake += loss.item()\n",
        "        correct_fake += count_correct(y, t)\n",
        "\n",
        "        # 本物の画像を使ってDiscriminatorを訓練\n",
        "        imgs_real= x.cuda()\n",
        "        t = torch.ones(x.size()[0], 1).cuda()  # 正解は1\n",
        "        y = discriminator(imgs_real)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
        "        loss_real += loss.item()\n",
        "        correct_real += count_correct(y, t)\n",
        "\n",
        "        # Generatorを訓練\n",
        "        noise = torch.randn(x.size()[0]*2, n_noise).cuda()  # バッチサイズを2倍にする\n",
        "        imgs_fake = generator(noise)  # 画像の生成\n",
        "        t = torch.ones(x.size()[0]*2, 1).cuda()  # 正解は1\n",
        "        y = discriminator(imgs_fake)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_gen.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_gen.step()  # Generatorのみパラメータを更新\n",
        "\n",
        "    loss_fake /= j+1  # 誤差\n",
        "    error_record_fake.append(loss_fake)\n",
        "    acc_fake = correct_fake / n_total  # 精度\n",
        "    acc_record_fake.append(acc_fake)\n",
        "\n",
        "    loss_real /= j+1  # 誤差\n",
        "    error_record_real.append(loss_real)\n",
        "    acc_real = correct_real / n_total  # 精度\n",
        "    acc_record_real.append(acc_real)\n",
        "\n",
        "    # 一定間隔で誤差と生成された画像を表示\n",
        "    if i % interval == 0:\n",
        "        print (\"Epochs:\", i)\n",
        "        print (\"Error_fake:\", loss_fake , \"Acc_fake:\", acc_fake)\n",
        "        print (\"Error_real:\", loss_real , \"Acc_real:\", acc_real)\n",
        "        generate_images(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aleBcXwqgGq"
      },
      "source": [
        "学習が進むにつれて、次第に明瞭な手書き数字画像が形作られていきます。  \n",
        "GeneratorはDiscriminatorをうまく騙せるように、DiscriminatorはGeneratorに騙されないように、互いに切磋琢磨した結果、本物に近い画像が生成されるようになりました。      \n",
        "なお、学習がうまく進まない場合もあるので、そのような場合は学習を最初からやり直してみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvxNus-jNWk3"
      },
      "source": [
        "### 誤差と正解率の推移\n",
        "学習中における、誤差と正解率の推移を確認します。  \n",
        "Discriminatorに本物画像を鑑定させた際の誤差の推移と、偽物画像を鑑定させた際の誤差の推移をグラフに表示します。  \n",
        "正解率の推移も表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIKYIQODJ0Q"
      },
      "source": [
        "# -- 誤差の推移 --\n",
        "plt.plot(range(len(error_record_fake)), error_record_fake, label=\"Error_fake\")\n",
        "plt.plot(range(len(error_record_real)), error_record_real, label=\"Error_real\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()\n",
        "\n",
        "# -- 正解率の推移 --\n",
        "plt.plot(range(len(acc_record_fake)), acc_record_fake, label=\"Acc_fake\")\n",
        "plt.plot(range(len(acc_record_real)), acc_record_real, label=\"Acc_real\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KvTaPccn5nm"
      },
      "source": [
        "最初、誤差は大きく変動しますが、ある程度時間が経過するとほぼ動かなくなります。  \n",
        "偽物画像を入力した際場合、Generatorは誤差を上げようとして、Discriminatorは下げようとするので、一種の均衡が生じています。  \n",
        "また、本物画像を入力した場合、Generatorは真贋の判定を防ぐように学習するので誤差を上げようとして、Discriminatorはこれを下げようとするので、こちらでも均衡が生じます。  \n",
        "  \n",
        "正解率について、Generatorが完璧であれば正解率は0.5になり、Discriminatorが完璧であれば正解率は1.0になるはずです。  \n",
        "正解率は偽物、本物ともに0.5-1.0の範囲に収まっているので、GeneratorとDiscriminatorの均衡がこちらでも観察されます。  \n",
        "GeneratorとDiscriminatorが競合するように学習し、その結果生じた均衡のなかで、少しずつ本物らしい画像が形作られていきます。  \n",
        "なお、乱数の値によっては両者がうまく均衡できない場合もあります。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0qZ81oX3Bk"
      },
      "source": [
        "## 演習\n",
        "GeneratorとDiscriminatorのバランスを、あえて崩してみましょう。  \n",
        "\n",
        "コードの以下の箇所に注目します。\n",
        "```\n",
        "        # Generatorを訓練\n",
        "        noise = torch.randn(x.size()[0]*2, n_noise).cuda()  # バッチサイズを2倍にする\n",
        "```\n",
        "ここを例えば以下のように変更し、両者のバランスに変更を加えてください。\n",
        "```\n",
        "        # Generatorを訓練\n",
        "        noise = torch.randn(x.size()[0]*4, n_noise).cuda()  # バッチサイズを4倍にする\n",
        "```\n",
        "これにより、結果がどのように変化するのか確かめてみましょう。  \n",
        "\n"
      ]
    }
  ]
}